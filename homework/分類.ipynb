{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset for the AND function\n",
    "x = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "\n",
    "y = np.array([0,0,0,1])\n",
    "\n",
    "# Build the network\n",
    "# sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim=2, activation='relu')) \n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(x,y,epochs=1000)\n",
    "\n",
    "pred = model.predict(x)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = load_iris() # load the iris dataset\n",
    "\n",
    "x = iris_data.data\n",
    "y_ = iris_data.target.reshape(-1, 1) # Convert data to a single column\n",
    "\n",
    "# One Hot encode the class labels\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y = encoder.fit_transform(y_)\n",
    "#print(y)\n",
    "\n",
    "# Split the data for training and testing\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.20)\n",
    "\n",
    "# Build the model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(5, input_dim=4, activation='relu'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Adam optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer = 'Adam', metrics=['accuracy'])\n",
    "\n",
    "print('Neural Network Model Summary: ')\n",
    "print(model.summary())\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_x, train_y, verbose=2, batch_size=5, epochs=200)\n",
    "\n",
    "# Test on unseen data\n",
    "results = model.evaluate(test_x, test_y)\n",
    "\n",
    "print('Final test set loss: {:4f}'.format(results[0]))\n",
    "print('Final test set accuracy: {:4f}'.format(results[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 - 0s - loss: 0.6644 - accuracy: 0.8230 - val_loss: 0.2883 - val_accuracy: 0.9204\n",
      "Epoch 2/10\n",
      "48000/48000 - 0s - loss: 0.2659 - accuracy: 0.9249 - val_loss: 0.2202 - val_accuracy: 0.9407\n",
      "Epoch 3/10\n",
      "48000/48000 - 0s - loss: 0.2071 - accuracy: 0.9424 - val_loss: 0.1840 - val_accuracy: 0.9498\n",
      "Epoch 4/10\n",
      "48000/48000 - 0s - loss: 0.1699 - accuracy: 0.9530 - val_loss: 0.1596 - val_accuracy: 0.9559\n",
      "Epoch 5/10\n",
      "48000/48000 - 0s - loss: 0.1434 - accuracy: 0.9606 - val_loss: 0.1432 - val_accuracy: 0.9603\n",
      "Epoch 6/10\n",
      "48000/48000 - 0s - loss: 0.1235 - accuracy: 0.9665 - val_loss: 0.1301 - val_accuracy: 0.9632\n",
      "Epoch 7/10\n",
      "48000/48000 - 0s - loss: 0.1069 - accuracy: 0.9714 - val_loss: 0.1189 - val_accuracy: 0.9665\n",
      "Epoch 8/10\n",
      "48000/48000 - 0s - loss: 0.0942 - accuracy: 0.9745 - val_loss: 0.1132 - val_accuracy: 0.9682\n",
      "Epoch 9/10\n",
      "48000/48000 - 0s - loss: 0.0839 - accuracy: 0.9772 - val_loss: 0.1071 - val_accuracy: 0.9689\n",
      "Epoch 10/10\n",
      "48000/48000 - 0s - loss: 0.0745 - accuracy: 0.9804 - val_loss: 0.1017 - val_accuracy: 0.9716\n",
      "10000/10000 [==============================] - 0s 25us/sample - loss: 0.0958 - accuracy: 0.9716\n",
      "\n",
      "\t[Info] Accuracy of testing data = 97.2%\n",
      "[7 2 1 0 4 1 4 9 6 9]\n"
     ]
    }
   ],
   "source": [
    "# 載入 MNIST 資料庫的訓練資料，並自動分為『訓練組』及『測試組』\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "y_TrainOneHot = np_utils.to_categorical(y_train) \n",
    "y_TestOneHot = np_utils.to_categorical(y_test) \n",
    "\n",
    "#將 image 以 reshape 轉換為二維 ndarray 並進行 normalization\n",
    "X_train_2D = X_train.reshape(60000, 28*28).astype('float32')  \n",
    "X_test_2D = X_test.reshape(10000, 28*28).astype('float32')  \n",
    "x_Train_norm = X_train_2D/255\n",
    "x_Test_norm = X_test_2D/255\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=256, input_dim=784, activation='relu')) \n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "\n",
    "# 進行訓練, 訓練過程會存在 train_history 變數中\n",
    "train_history = model.fit(x=x_Train_norm, y=y_TrainOneHot, validation_split=0.2, epochs=10, batch_size=800, verbose=2)  \n",
    "\n",
    "scores = model.evaluate(x_Test_norm, y_TestOneHot)  \n",
    "print()  \n",
    "print(\"\\t[Info] Accuracy of testing data = {:2.1f}%\".format(scores[1]*100.0))  \n",
    "\n",
    "# 預測(prediction)\n",
    "X = x_Test_norm[0:10,:]\n",
    "predictions = model.predict_classes(X)\n",
    "# get prediction result\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
